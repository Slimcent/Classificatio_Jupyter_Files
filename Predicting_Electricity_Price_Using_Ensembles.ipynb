{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3252e6",
   "metadata": {},
   "source": [
    "Ensemble models combine predictions from multiple individual models to improve overall performance and robustness. \n",
    "They leverage the strengths of various algorithms to produce a final prediction that is often more accurate and less prone to overfitting than any single model alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2525ed",
   "metadata": {},
   "source": [
    "There are several types of ensemble methods, which are;\n",
    "\n",
    "Bagging (Bootstrap Aggregating)\n",
    "How it Works: Multiple copies of the same algorithm are trained on different subsets of the training data (created by bootstrapping, which involves sampling with replacement). The final prediction is made by aggregating the predictions from all models, typically by averaging for regression tasks and majority voting for classification tasks.\n",
    "Example: Random Forest is a popular bagging algorithm that uses decision trees as the base models.\n",
    "\n",
    "Boosting\n",
    "How it Works: Models are trained sequentially, where each new model focuses on the errors made by the previous models. The predictions from all models are combined, often with weights assigned to each model based on its performance.\n",
    "Example: AdaBoost and Gradient Boosting Machines (GBM) are common boosting techniques.\n",
    "\n",
    "Stacking (Stacked Generalization)\n",
    "How it Works: Multiple models (base learners) are trained on the same dataset. A meta-model (or second-level model) is then trained on the outputs of the base models to make the final prediction. This meta-model learns how to best combine the predictions of the base models.\n",
    "Example: You might use logistic regression as a meta-model to combine the outputs of several different base classifiers.\n",
    "\n",
    "Voting\n",
    "How it Works: Multiple models (typically of different types) are trained, and their predictions are combined through a voting scheme. For classification tasks, it could be majority voting or weighted voting, and for regression, it could be averaging.\n",
    "Example: A simple voting classifier that uses the majority vote of decision trees, support vector machines, and k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd7c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705117c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
